{
    "model_hyperparameters": {
        "n_hidden_layers": 1,
        "n_units_in_hidden_layers": 128,
        "activation_function": "relu",
        "dropout": 0.3
    },
    "training_parameters": {
        "epochs": 150,
        "batch_size": 32,
        "verbose": 1
    }
}
